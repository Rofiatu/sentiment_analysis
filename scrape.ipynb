{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twikit import Client, TooManyRequests\n",
    "import asyncio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"error\", category=DeprecationWarning, module=\"html.parser\")\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import httpx\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "import csv\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "\n",
    "# 1 - log in to twitter\n",
    "\n",
    "client = Client('en-US')\n",
    "await client.login(auth_info_1='user_name', password='password') # Comment out after first log-in\n",
    "client.save_cookies('cookies.json') # Comment out after first log-in\n",
    "client.load_cookies(path='cookies.json')\n",
    "\n",
    "# 2 - Define Parameters and Scrape Data\n",
    "\n",
    "# Query and limits\n",
    "query = \"(#SevenDoors OR #SevenDoorsOnNetflix OR #ThinlineTheMovie OR #Thinline OR #ThinLineTheMovie OR #EverybodyLovesJenifa) lang:en\" # Specify all your queries\n",
    "min_tweets = 2000\n",
    "tweet_count = 0\n",
    "new_tweets = None\n",
    "\n",
    "# To cater to time-outs\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=20))\n",
    "async def fetch_tweets(client, query, new_tweets=None):\n",
    "    if new_tweets is None:\n",
    "        print(f'{datetime.now()} - Fetching initial tweets...')\n",
    "        return await client.search_tweet(query, product='Top')\n",
    "    else:\n",
    "        wait_time = randint(5, 20)\n",
    "        print(f'{datetime.now()} - Waiting {wait_time} seconds before fetching next tweets...')\n",
    "        await asyncio.sleep(wait_time)\n",
    "        return await new_tweets.next()\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('file_name.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet_count', 'Time_of_Creation', 'Tweet', 'Hashtags', 'Retweets', 'Likes']) # Specify information you'd like to see for each tweet\n",
    "\n",
    "    # Main loop for fetching tweets\n",
    "    while tweet_count < min_tweets:\n",
    "        try:\n",
    "            # Fetch tweets with retry and timeout handling\n",
    "            new_tweets = await fetch_tweets(client, query, new_tweets)\n",
    "            \n",
    "        except TooManyRequests as e:\n",
    "            # Handle rate-limiting\n",
    "            rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            print(f'{datetime.now()} - Rate limit reached: Waiting until {rate_limit_reset}')\n",
    "            wait_time = rate_limit_reset - datetime.now()\n",
    "            await asyncio.sleep(wait_time.total_seconds())\n",
    "            continue\n",
    "        except httpx.RequestError as e:\n",
    "            # Handle other HTTP errors\n",
    "            print(f'{datetime.now()} - Network error occurred: {e}')\n",
    "            continue\n",
    "\n",
    "        if not new_tweets:\n",
    "            print(f'{datetime.now()} - No more tweets available!')\n",
    "            break\n",
    "\n",
    "        # Process and save tweets\n",
    "        batch_count = 0\n",
    "        for tweet in new_tweets:\n",
    "            tweet_count += 1\n",
    "            batch_count += 1\n",
    "            writer.writerow([\n",
    "                tweet_count,\n",
    "                tweet.created_at,\n",
    "                tweet.text,\n",
    "                tweet.hashtags,\n",
    "                tweet.retweet_count,\n",
    "                tweet.favorite_count\n",
    "            ])\n",
    "\n",
    "            if tweet_count >= min_tweets:\n",
    "                break\n",
    "\n",
    "        print(f'{datetime.now()} - {batch_count} tweets scraped in this batch. Total: {tweet_count}')\n",
    "\n",
    "print(f'{datetime.now()} - Completed scraping! {tweet_count} tweets found!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sentiment_analysis)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
